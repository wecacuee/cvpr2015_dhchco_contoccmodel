%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LaTeX poster template
% Created by Nathaniel Johnston
% August 2009
% http://www.nathanieljohnston.com/2009/08/latex-poster-template/
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[handout,final]{beamer}
\usepackage{beamerposter}
\usepackage{graphicx}			% allows us to import images

\usepackage{ragged2e}
\usepackage{booktabs}
\usepackage{bm}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{booktabs}

\usetikzlibrary{trees,shadows}

\tikzset{/tikz/x=2.5cm}
\tikzset{/tikz/y=2.5cm}

\newcommand{\Ptransmission}{P_{\textit{transmission}}}%
\newcommand\RotText[1]{\rotatebox{90}{\parbox{1.7cm}{\centering#1}}}
\newcommand{\bepsilon}{{\bm{\epsilon}}}
\newcommand{\meandepth}[1]{\nu_#1}
\newcommand{\bLambda}{\bm{\Lambda}}

%-----------------------------------------------------------
% Define the column width and poster size
% To set effective sepwid, onecolwid and twocolwid values, first choose how many columns you want and how much separation you want between columns
% The separation I chose is 0.024 and I want 4 columns
% Then set onecolwid to be (1-(4+1)*0.024)/4 = 0.22
% Set twocolwid to be 2*onecolwid + sepwid = 0.464
%-----------------------------------------------------------

\newlength{\sepwid}
\newlength{\onecolwid}
\newlength{\twocolwid}
\newlength{\threecolwid}
\setlength{\paperwidth}{48in}
\setlength{\paperheight}{36in}
\setlength{\sepwid}{0.024\paperwidth}
\setlength{\onecolwid}{0.22\paperwidth}
\setlength{\twocolwid}{0.464\paperwidth}
\setlength{\threecolwid}{0.708\paperwidth}
\setlength{\topmargin}{-0.5in}
\usetheme{confposter}
\usepackage{exscale}

\input{preamble}


%-----------------------------------------------------------
% The next part fixes a problem with figure numbering. Thanks Nishan!
% When including a figure in your poster, be sure that the commands are typed in the following order:
% \begin{figure}
% \includegraphics[...]{...}
% \caption{...}
% \end{figure}
% That is, put the \caption after the \includegraphics
%-----------------------------------------------------------

\usecaptiontemplate{
\small
\structure{\insertcaptionname~\insertcaptionnumber:}
\insertcaption}

%-----------------------------------------------------------
% Define colours (see beamerthemeconfposter.sty to change these colour definitions)
%-----------------------------------------------------------

% \setbeamercolor{block title}{fg=ngreen,bg=white}
% \setbeamercolor{block body}{fg=black,bg=white}
% \setbeamercolor{block alerted title}{fg=white,bg=dblue!70}
% \setbeamercolor{block alerted body}{fg=black,bg=dblue!10}

%-----------------------------------------------------------
% Name and authors of poster/paper/research
%-----------------------------------------------------------

\title{A Continuous Occlusion Model for Road Scene Understanding}
\author{Vikas Dhiman$^\dagger$ \and Quoc-Huy Tran$^*$ \and Jason J. Corso$^\dagger$ \and Manmohan Chandraker$^*$}
\institute{$^\dagger$University of Michigan, Ann Arbor, MI \qquad $^*$NEC Laboratories America, Cupertino, CA}

%-----------------------------------------------------------
% Start the poster itself
%-----------------------------------------------------------

\begin{document}

\begin{frame}[t]
  \begin{columns}[t]												% the [t] option aligns the column's content at the top
    \begin{column}{\sepwid}\end{column}			% empty spacer column
    \begin{column}{\onecolwid}
      \begin{block}{Introduction}
        \begin{figure}[!!t]
          \input{Source/figure_introduction.tex}
        \end{figure}
        \textbf{Contributions}:
        \begin{itemize}
          \item We propose a novel continuous occlusion model in 3D that is
            physically interpretable.
          \item Unified occlusion handling for point tracks in SFM and bounding boxes and detection scores in object detection.
          \item Application of our proposed model to association of point tracks with both static and moving objects, improving over motion segmentation and occlusion-unaware baselines.
          \item Application of our unified formulation to 3D localization of traffic participants in road scenes.
        \end{itemize}
      \end{block}

      \begin{block}{Continuous Occlusion Model}
		\textbf{Occupancy Model}: Traffic participants are represented as translucent 3D ellipsoids whose opacity is maximum at the center and falls off towards the edges.
        \begin{align}
          f^i_{\textit{occ}}(\bx) = \cL(\bx; \bp_i, \bSigma_i)
        \end{align}
		\textbf{Image Formation}: A point on an object is observed in the camera if: 1) the back-projected ray from the observed image pixel is transmitted through free space until it reaches the object, and 2) the ray encounters an opaque enough object surface and is reflected.		
        \begin{align}
          P^{ij}_{\textit{observation}} = P^{ij}_{\textit{reflection}}P^{j}_{\textit{transmission}}
        \end{align}
        \begin{align}
          P^{ij}_{\textit{reflection}}(\lambda) = \frac{1}{Z}(\max \{0, \nabla {f^i_{occ}}(\bx_j)^\top \ray \})^2
        \end{align}
        \begin{align}
	        \occftot = \sum_i \occf      
        \end{align}
        \begin{align}
          P^{j}_{\textit{transmission}}(\lambda) &= \prod_{c}^{\lambda} (1 - \occft{\lambda \ray})^{d\lambda}\\
          &\approx \prod_i (1 - \cL_u (\bu; \bmu_i, \bGamma_i) \cL_{\lambda}(\lambda; \meandepth{i}))
        \end{align}

        % \begin{figure}
        %   \usetikzlibrary{calc}
        %   \centering
        %   \begin{tikzpicture}
        %     \input{Source/reflectiontransmissiongraph.tex}
        %   \end{tikzpicture}
        %   \vspace{-0.3cm}
        %   \caption{\small We represent objects as translucent ellipsoids, which leads to the formulation of transmission and reflection probabilities. This figure shows the reflection probability for the first object (in violet), which has high values around the camera-facing side of the object. Also, note that the transmission probability is inversely proportional to occupancy.}
        %   \label{fig:reflectiontransimission}
        %   \vspace{-0.3cm}
        % \end{figure}
        \begin{figure}
  		  \usetikzlibrary{calc}
  		  \centering
  		  \begin{tikzpicture}
    			\input{Source/reflectiontransmissiongraph.tex}
  		  \end{tikzpicture}  			
  		\end{figure}
        \begin{figure}
          \centering
          \includegraphics[width=0.5\columnwidth]{results/plotPtransmission_exact_vs_approx_pt_vis-small.png}
          \includegraphics[trim=0 0 0.3 0, clip, width=0.5\columnwidth]{results/plotPtransmission_exact_vs_approx_embedded_fonts.pdf}          
        \end{figure}
      \end{block}

    \end{column}
    \begin{column}{\sepwid}\end{column}			% empty spacer column
    \begin{column}{2.0\onecolwid}
      \begin{block}{Experiments}
        \begin{columns}[t]
          \column{1.000\onecolwid}
          \begin{table}
            \begin{tabular}{lrrrr}
              \toprule
              Point tracks & Ours & BBox & BM~\cite{Brox_Malik_2010} & RAS~\cite{Rao_etal_2010}\\
              \midrule
              Dynamic \& occluded         & \textbf{13.2} & 21.3 & 30.9 & 30.1 \\
              Occluded		              & \textbf{15.7} & 19.8 & 39.5 & 37.8 \\
              Dynamic		              & \textbf{6.6} & 11.4 & 15.3 & 17.7 \\
              All		                  & \textbf{8.6} & 12.6 & 21.9 & 21.5 \\
              \bottomrule
            \end{tabular}
            \caption{\small Mean association errors on different sets of input point tracks over all sequences. Errors are in terms of average fractions of foreground points incorrectly associated to objects per sequence.}
          \end{table}
          \column{1.000\onecolwid}
          \begin{table}
            \begin{tabular}{lrr}
              \toprule
              Method & t & dim \\
              \midrule
              Point cloud fitting
              & 6.87 & 4.02\\
              Initialization by~\cite{Song_Chandraker_2014}
              & 5.61 & 3.23\\
              $\EnergyTrackNoOcc + \Energy{detectNoOcc} +\EnergySize+\EnergyDyn$ 
              & 3.95  & 1.72\\        
              $\EnergyTrackNoOcc + \Energy{detect} +\EnergySize+\EnergyDyn$        
              & 4.81  & 2.16\\        
              $\EnergyTrack + \Energy{detectNoOcc} +\EnergySize+\EnergyDyn$      
              & 4.05  & {\bf 1.59}\\        
              $\EnergyTrack + \Energy{detect} +\EnergySize+\EnergyDyn$             
              & {\bf 3.24}  & 2.16\\
              \bottomrule
            \end{tabular}
            \caption{\small Localization experiment results with different combinations of energies. We report translation error (t) and dimension error (dim) in meters per car. Yaw angles for static objects are not optimized by our model. These experiments use the set of occluded tracks to demonstrate the effect of our modeling.}
          \end{table}
        \end{columns}
        \newlength{\tblimgwidth}
        \setlength{\tblimgwidth}{0.080\textwidth}
        \input{Source/figure_assoc_qualitative.tex}
        \begin{figure}[!!t]
          \centering
          \includegraphics[trim=1.0in 0.4in 1.0in 0.2in, clip, width=0.9\textwidth]{results/plotErrorBarEvalAssocCoeffAllSequence.pdf}
		  \caption{\small Association errors on different sets of input point tracks. Numbers on the horizontal axis represent sequence numbers in the KITTI raw dataset. Errors are in terms of average fractions of foreground points incorrectly associated to objects per sequence.}
        \end{figure}
      \end{block}
      \smallsize{
      \textbf{Acknowledgements}
      This work was part of V.~Dhiman's internship at NEC Laboratories America, Cupertino. V.~Dhiman and J.~J.~Corso were also supported by NSF NRI IIS 1522904.}
    \end{column}
    \begin{column}{\sepwid}\end{column}			% empty spacer column
    \begin{column}{\onecolwid}
      \begin{block}{Unified Occlusion Models}  
      
		\begin{table}[!!t]
		\centering\footnotesize
		\begin{tabular}{|l|l|l|}
		\hline
		 & Symbol & Description \\
		\hline
		\hline
		\multirow{2}{*}{\rotatebox{90}{Input}} & $\bu_j(t)$ & 2D feature track $j$ at time $t$ \\
		 & $\textbf{d}^i(t)$ & 2D detection bounding box of object $O_i$ at time $t$ \\
		\hline
		\hline
		\multirow{8}{*}{\RotText{Initialization with~\cite{Song_Chandraker_2014}}} & $\bp^c(t)$ & Position of camera at time $t$ \\
		 & $\bomega^c(t)$ & Orientation of camera at time $t$ \\
		 & $\bp_0^i(t)$ & Initial position of object $O_i$ at time $t$ \\
		 & $\bomega_0^i(t)$ & Initial orientation of object $O_i$ at time $t$ \\
		 & $\bB_0^i$ & Initial 3D dimensions of object $O_i$ \\
		\hline
		\hline
		\multirow{4}{*}{\rotatebox{90}{Output}} & $P^{ij}_{\text{assoc}}$ & Probability of assigning feature track $j$ to object $O_i$ \\	
		 & $\bp^i(t)$ & Position of object $O_i$ at time $t$ \\
		 & $\bomega^i(t)$ & Orientation of object $O_i$ at time $t$ \\
		 & $\bB^i$ & 3D dimensions of object $O_i$ \\
		\hline
		\end{tabular}
		\end{table}           
      
      \textbf{Object-Point Association:}
        \begin{align}
          a^{ij}(\lambda) = P^{ij}_{\textit{reflection}}P^{j}_{\textit{transmission}}
        \end{align}
        \begin{align}
          P^{ij}_{\textit{assoc}} = \frac{1}{Z'}\int_0^{\infty} a^{ij}(\lambda) \exp(-E^{ij}_{\textit{reproj}}(\lambda))d\lambda
        \end{align}

	  \textbf{3D Object Localization:}
		\begin{figure}
			\newcommand{\imagewidth}{17cm}
		    \input{Source/scenelayoutoverlayCity0961} \\
		    \input{Source/graphical_model_multiple}        
        \end{figure}	
        \begin{multline*}
          -\log{P(\{ \bp^i(t) , \bomega^i(t) , \bB^i(t) \} | \{\bu_j(t)\} , \{\textbf{d}^i(t)\} )} = \\
          -Z'' 
          + \sum_{t=s_i}^{e_i} \lambda_{\text{track}}\EnergyTrack
          +  
          \sum_{t=s_i}^{e_i} \sum_{i=1}^N  
          \left(
            \lambda_{\text{detect}}\Energy{detect}
            + \lambda_{\text{dyn}}\EnergyDyn    
            + \lambda_{\text{size}}\EnergySize
          \right)
          \enspace
        \end{multline*}        
        \begin{align}
		  \pEnergy{track} = \sum_{i=1}^{N} \sum_{j = 1}^{M} \int_0^\infty a^{ij}(\lambda) E^{ij}_{\textit{reproj}}(\lambda) d\lambda
		\end{align}        
        \begin{equation}
			S(\textbf{d}^i(t)) = \sum_k A_k \exp \left( -\bepsilon_k^{i}(t)^\top \bLambda_k^{-1} \bepsilon_k^{i}(t) \right)
		\end{equation}		
		\begin{align}
		  \Theta_{i}(\bu, \meandepth{i}) = 1 - \Ptransmission(\bu, \meandepth{i})
		\end{align}		
		\begin{align}
		  \Energy{detect} = \frac{1}{S'(\textbf{d}^i(t))}
		\end{align}
        
                
        % \begin{figure}
        %   \centering
        %   \newcommand{\imagewidth}{\onecolwid}
        %   \input{Source/scenelayoutoverlayCity0961}
        %   \caption{A sample road scene with the unknowns of each car modeled as random variables. 
        %   The relating energies are shown in Figure~\ref{fig:graphmodel}}
        % \end{figure}

      \end{block}
      \begin{block}{Conclusion}
        \begin{itemize}
          \item A physically interpretable, continuous model for occlusion reasoning in 3D.
          \item Unified models for various applications of scene understanding such as object-point association and 3D localization.
          \item Future work will explore speeding up graphical model inference and more detailed object representation.
        \end{itemize}
      \end{block}

      \begin{block}{References}
      \scriptsize{
        \bibliography{poster}
        \bibliographystyle{ieee}
      }
      \end{block}
    \end{column}
  \end{columns}
\end{frame}

\end{document}
