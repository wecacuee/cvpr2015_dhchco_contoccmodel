\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{verbatim}
\usepackage{bm}
\usepackage{microtype}
\usepackage{url}
\usepackage{multirow}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{booktabs} % for better tables

\usepackage{color}
\newcommand{\hili}[1]{\colorbox{yellow}{#1}}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\input{preamble}
\newcommand{\xmin}{x_\text{min}}
\newcommand{\ymin}{y_\text{min}}
\newcommand{\xmax}{x_\text{max}}
\newcommand{\ymax}{y_\text{max}}
\DeclareMathOperator*{\argmin}{\arg\min}
\input{Source/drawingslib}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{2072} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{A Continuous Occlusion Model for Road Scene Understanding}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}


%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW

As suggested by Reviewers 1 and 2, we have added Table~\ref{tab:notations} for improving the exposition of our methods. In addition to feature tracks and detection bounding boxes, we use camera poses and 3D object bounding boxes (estimated respectively using SFM and assuming detection bounding boxes lie on the ground with priors on object dimensions) for computing object-point association probabilities and initializing 3D object localization methods. 

\begin{table}\centering\footnotesize
\begin{tabular}{|l|l|l|}
\hline
& Symbol & Description \\
\hline
\hline
\multirow{2}{*}{\rotatebox{90}{Input}} & $\bu_j(t)$ & 2D feature track $j$ at time $t$ \\
					   	& $\bb{i}$ & 2D detection bounding box of object $O_i$ at time $t$ \\
\hline
\hline
\multirow{5}{*}{\rotatebox{90}{Estimated}} & $\bp^c(t)$ & Position of camera at time $t$ \\
						& $\bomega^c(t)$ & Orientation of camera at time $t$ \\
						& $\bp_0^i(t)$ & Initial position of object $O_i$ at time $t$ \\
					    & $\bomega_0^i(t)$ & Initial orientation of object $O_i$ at time $t$ \\
						& $\bB_0^i$ & Initial 3D dimensions of object $O_i$ (independent of time $t$) \\

\hline
\hline
\multirow{4}{*}{\rotatebox{90}{Output}} & $P^{ij}_{\text{assoc}}$ & Probability of associating feature track $j$ with object $O_i$ \\	
						& $\bp^i(t)$ & Position of object $O_i$ at time $t$ \\
					    & $\bomega^i(t)$ & Orientation of object $O_i$ at time $t$ \\
						& $\bB^i$ & 3D dimensions of object $O_i$ (independent of time $t$) \\
\hline
\end{tabular}
\caption{Notation of input and output.}
\label{tab:notations}
\end{table}

Reviewers 1 and 2 mentioned the coarse representation of objects (3D ellipsoids), our aim is to balance between the ease of analytical formulations and the practical requirements of object-point association. Reviewer 2 further said that we demonstrated only for a single but important object category (car), which is because it is the only one that we have ground truth data for (KITTI dataset), and there are very few obstacles to apply our methods to other categories as long as we have feature tracks and detection bounding boxes.

Regarding the complicated graphical model and computational aspect, our current work focuses on the flexibility of our occlusion model, and there are many potential applications while object localization is one of them. Future work will invest in speeding up the inference. In the following, we will respond to each reviewer's comments:

\section{Reviewer 1}

We thank Reviewer 1 for the suggestion of including the errors corresponding to the initial estimates in Table~\ref{tab:localization}, which clearly shows the benefits of energy minimization.   

\begin{table}\centering\footnotesize
\begin{tabular}{|l|l|l|}
\hline
Energy & t & dim \\
\hline
\hline
Baseline & \hili{XXX} & \hili{XXX} \\
Initialization & \hili{XXX} & \hili{XXX} \\
$\EnergyTrackNoOcc + \EnergyBBoxNoOcc +\EnergySize+\EnergyDyn$ 
& 3.95  & 1.72\\        
$\EnergyTrackNoOcc + \EnergyBBox +\EnergySize+\EnergyDyn$        
& 4.81  & 2.16\\        
$\EnergyTrack + \EnergyBBoxNoOcc +\EnergySize+\EnergyDyn$      
& 4.05  & {\bf 1.59}\\        
$\EnergyTrack + \EnergyBBox +\EnergySize+\EnergyDyn$             
& {\bf 3.24}  & 2.16\\
\hline
\end{tabular}
\caption{Localization experiment results.}
\label{tab:localization}
\end{table}

Equation 4: we use gradient occupancy vector $\nabla {f^i_{occ}}(\bx_j)$ since we want reflection probability to be high near object borders, $\max$ ensures that negative probability due to gradient in the direction opposite to the ray is clipped off, and squaring allows the function to be smooth near zero. We normalize $P^{ij}_{\textit{reflection}}(\lambda)$  with respect to different $\lambda$. Please refer to Figure 2 for an illustration of reflection probability.

We compute the normalization factor $Z'$ in Equation 13 numerically using importance sampling.

\section{Reviewer 2}

Instead of using binary functions, we model objects by translucent functions, which not only accounts for object shape uncertainty but also allows a continuous occlusion model that remains amenable to continuous optimization tools. 

Section 4.2: our apologies, we have included all objects in the first equation as follows:
\begin{multline*}
  -\log{P(\{ \bp^i(t) , \bomega^i(t) , \bB^i \} | \{\bu_j(t)\} , \{\bb{i}\} )} = -Z + \\ 
  \lambda_t \sum_{t=s_i}^{e_i} \EnergyTrack
  + 
  \lambda_d \sum_{t=s_i}^{e_i} \sum_{i=1}^N \EnergyBBox
  + 
  \lambda_{\text{dyn}} \sum_{i=1}^N \EnergyDyn
  + 
  \lambda_{\text{size}} \sum_{i=1}^N \EnergySize
  \enspace,
\end{multline*}
and have excluded object poses from the previous time step in Equation 19 as below:
\begin{align*}
\Energy{detect}(\{ \relp{i}{t} \}_i, \{\dimsn{i}\}_i ) = \frac{1}{S'(\bb{i})}.
\end{align*}

The number of objects is known a priori in our occlusion model (given by object tracking [2]) and is also provided to other methods such as BBox and RAS. Outlier feature tracks usually have high reprojection errors and hence low object-point association probabilities while outlier detection bounding boxes are likely to be removed by object tracking [2]. We use \hili{XXX} sequences from KITTI dataset, which have total \hili{XXX} frames. After running object tracking [2], there are total \hili{XXX} objects survived.

In object-point association experiments, the baseline method (BBox) uses 3D bounding boxes (though they are only for depth ordering). The crucial question now is how to probabilistically weigh points closer to the boundary of the 3D bounding box less than points inside the box and our occlusion model is in fact a principle way to do that same thing.

In localization experiments, we have tried [33] on a few images and it has higher localization accuracy than our method, which is mostly due to its detailed shape model. However, it needs a database of CAD models, takes about 30 mins for inference on a single image, and is a discrete model which is not suitable for continuous optimization tools. Alternatively, we have added the suggested baseline which robustly fits a 3D bounding box on the reconstructed point cloud (by SFM within detection bounding boxes) and relies on priors on object dimensions for unobservable dimensions. We have included the results of this baseline in Table~\ref{tab:localization}.

\section{Reviewer 3}

Transmission probability only indicates whether a ray is transmissible to a particular depth but does not provide information on which object obstructs the ray at that depth. Alternatively, this information is given by the reflection probability. Therefore, a combination of transmission and reflection probabilities is more suitable for explaining the image observations.

Regarding the concern about the superiority of our method in Figure 5, we focus on a probabilistic method to incorporate all available information for occlusion reasoning and it is not provided by previous works (in a sense this was also the goal of [32][33] which use CAD models).

\end{document}
