\section{Related Work}
\label{sec:related}

\paragraph{Occlusion handling} 
Occlusion handling plays an important role in many computer vision applications such as object detection and tracking. Methods that are capable of detecting occluded objects include \cite{Gao_etal_2011}, which trains different detectors for detecting specific parts of the object, and \cite{Pepik_etal_2013,Xiang_Savarese_2013}, which use 3D cues that are learned from a CAD database. These methods are either based on 2D cues~\cite{Gao_etal_2011} or often a discrete representation of occlusion behaviors~\cite{Pepik_etal_2013,Xiang_Savarese_2013}, e.g., in terms of a set of occlusion masks. In contrast, our occlusion model is fully 3D and a continuous representation, which enables the use of various continuous optimization tools. For object tracking, occlusions are usually handled by a set of occluder patterns~\cite{Kwak_etal_2012,Wu_Nevatia_2007}, which is also a discrete representation. A notable exception is the work of Milan et al.~\cite{Milan_etal_2014}, which explicitly models object occlusions in continuous domain. However, their work is based on 2D ellipses while we use 3D ellipsoids, which are more principled and meaningful for tackling occlusions in 3D space. Moreover, our formulations have more general applications, especially 3D scene understanding such as 3D localization and reconstruction.

\paragraph{Motion segmentation}
Motion segmentation has actively been studied in the literature. Previous work can roughly be categorized into algebraic/factorization methods~\cite{Costeria98,Vidal03,Vidal04}, statistical methods~\cite{Kanatani01,Gruber04,Rao08} and clustering methods~\cite{Yan06,Goh07}. Some recent efforts include robust algebraic segmentation with hybrid perspective constraints~\cite{Rao_etal_2010} and spectral clustering with point track spatial affinity~\cite{Brox_Malik_2010}. The above methods usually exploit the fact that point tracks of a particular moving object tend to follow similar motion patterns. Therefore, they cannot segment static objects due to no motion cues. In contrast, our method for point-to-object association is relatively independent of object motions and hence does not suffer from static objects. 

\paragraph{3D localization}
One of the vital goals of 3D scene understanding is to localize the 3D positions and orientations of objects in complex scenes. For instance, using stereo imagery, several visual cues are combined in \cite{Geiger_etal_2014} to simultaneously determine object locations and a rough intersection topology. Notable monocular frameworks for 3D localization include \cite{Wojek_etal_2013}, which uses partial object detectors for handling occlusions, and \cite{Zia_etal_2013,Zia_etal_2014}, which learn a detailed part-based representation of objects from annotated CAD models for reasoning about mutual occlusions. Generally speaking, the above methods are based on a discrete representation of occlusion behaviors. In contrast, leveraging on our occlusion model, we further develop unified formulations for both point track and bounding box energies, which are continuous and occlusion-aware, leading to an increase in 3D localization accuracy.