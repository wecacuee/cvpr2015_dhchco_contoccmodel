\section{Related Work}
\label{sec:related}

%An application for our occlusion modeling is to determine point track associations in scenes with multiple objects. For moving objects, this is within the purview of motion segmentation, which has been actively studied \cite{Tron_Vidal_2007,Rao_etal_2010}. This also motivates further applications such as object segmentation based on point trajectories \cite{Brox_Malik_2010}. Motion segmentation is also used within multibody structure from motion (SFM) frameworks \cite{Ozden_etal_2010,Kundu_etal_2011,Namdev2012}. In contrast to these works, our formulation does not distinguish between moving and static objects and also explicitly reasons about occlusions due to 3D object geometries for associating point tracks to individual objects.

\paragraph{Motion segmentation}
Motion segmentation has actively been studied in the literature. Previous work can roughly be categorized into algebraic methods~\cite{}, statistical methods~\cite{} and clustering methods~\cite{}. Some recent efforts include robust algebraic segmentation with hybrid perspective constraints~\cite{} and spectral clustering with point track spatial affinity~\cite{}. The above methods usually exploit the fact that point tracks of a particular moving object tend to follow similar motion patterns. Therefore, they cannot segment static objects due to no motion cues. In contrast, our method is relatively independent of object motions and hence does not suffer from static objects. 

\paragraph{Occlusion handling}
Occlusion handling plays an important role in many computer vision applications such as object detection and tracking. Methods that are capable of detecting occluded objects include~\cite{}, which trains different object part detectors, and~\cite{}, which learns 3D cues from a CAD database. These methods are either based on 2D cues~\cite{} or often a discrete representation of occlusion behavior~\cite{}. In contrast, our occlusion model is fully 3D and allows for a continuous representation. For object tracking, occlusions are often handled by a set of occluder patterns~\cite{}. A notable exception is~\cite{}, which explicitly models object occlusions in continuous domain to determine the visibility of each object. ...

%Occlusions have also been handled in tracking-by-detection frameworks by considering occluder patterns in the image \cite{Kwak_etal_2012,Wu_Nevatia_2007}. A notable exception is the work of Milan et al.~\cite{Milan_etal_2014} that explicits models occlusion in the continuous domain to determine a visibility for each object in multi-target tracking. However, the occlusion model in \cite{Milan_etal_2014} is essentially the overlap of image projections of a Gaussian representation of the object. Our occlusion modeling is much more general in determining the probability of a point in space as belonging to an object. While it can also be used to determine a visibility ratio similar to \cite{Milan_etal_2014}, it can have far more general applications and can be quantitatively evaluated, as shown by our experiments on point track associations.

\paragraph{3D localization}
One of the central goals of 3D scene understanding is to localize the 3D positions and orientations of objects in complex scenes. For instance, using stereo imagery, several visual cues are combined in \cite{Geiger_etal_2014} to simultaneously determine object locations and a rough intersection topology. Similar to us, other works have also considered monocular frameworks. Notably, occlusions are explicitly handled in \cite{Wojek_etal_2013} by considering partial object detectors. A detailed part-based representation of objects based on annotated CAD models is used for monocular scene understanding in \cite{Zia_etal_2013,Zia_etal_2014}, which also allows reasoning about mutual occlusions between objects. In contrast to these works, our monocular framework uses a physical modeling of occlusion in continuous space, which makes it more general, extensible and amenable for continuous optimization.


